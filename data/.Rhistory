summary(p)
str(raw_data)
m = glm(admit ~ rank , data = raw_data, family = 'binomial')
summary(m)
p = predict(m, newdata = raw_data, type='response')
summary(p)
df = data.frame(p)
sum(df$p > 0.5)
m = glm(admit ~ . , data = raw_data, family = 'binomial')
summary(m)
p = predict(m, newdata = raw_data, type='response')
summary(p)
df = data.frame(p)
sum(df$p > 0.5)
m = glm(admit ~ gre , data = raw_data, family = 'binomial')
summary(m)summary(m)summary(m)
summary(m)
help(glm)
m = glm(admit ~ . , data = raw_data, family = binomial(link='probit'))
help(glm)
summary(m)
p = predict(m, newdata = raw_data, type='response')
summary(p)
df = data.frame(p)
sum(df$p > 0.5)
sum(df$p >= 0.5)
summary(p)
table(raw_data$admit)
p = predict(m, newdata = raw_data)
summary(p)
p = predict(m, newdata = raw_data, type='response')
summary(p)
coef(m)
c = coef(m)
exp(c)
str(raw_data)
raw_data$result = coef[1] + coef[2] * raw_data$gre + coef[3] * raw_data$gpa + coef[4] * raw_data$rank
raw_data$result = c[1] + c[2] * raw_data$gre + c[3] * raw_data$gpa + c[4] * raw_data$rank
raw_data
c = coef(m)
c
raw_data$result = exp(c[1] + c[2] * raw_data$gre + c[3] * raw_data$gpa + c[4] * raw_data$rank)
raw_data
raw_data$result = 1 / (1 + exp(-(c[1] + c[2] * raw_data$gre + c[3] * raw_data$gpa + c[4] * raw_data$rank)))
raw_data
sum(raw_data$result > 0.5)
c
c[2]
sum(raw_data$result > 0.5)
p = predict(m, newdata = raw_data, type='response')
summary(p)
df = data.frame(p)
sum(df$p >= 0.5)
sum(df$p >= 1)
sum(df$p < 0)
sum(df$p <= 0)
sum(df$p <= 0.3)
train_index = sample(1:nrow(data), size = 100, replace = FALSE)
train_index = sample(1:nrow(data), size = 100, replace = F)
data = iris
set.seed(100)
train_index = sample(1:nrow(data), size = 100, replace = F)
train_index
train_data = data[train_index,]
train_data
str(train_data)
test_data = data[-train_index,]
library(nnet)
test_data = data[-train_index,]
levels(train_data$Species)
train_data$Species = relevel(train_data$Species, 'virginica')
help(levels)
mlogit = multinom(Species ~ . , data = train_data)
summary(mlogit)
levels(train_data$Species)
help(relevel)
predict(mlogit, newdata = data)
summary([])
summary(p)
summary(mlogit)
p = predict(mlogit, newdata = data)
summary(p)
p = predict(mlogit, newdata = test_data)
summary(p)
table(test_data$Species)
summary(mlogit)
set.seed(101)
train_index = sample(1:nrow(data), size = 100, replace = F)
train_data = data[train_index,]
str(train_data)
test_data = data[-train_index,]
levels(train_data$Species)
train_data$Species = relevel(train_data$Species, 'virginica')
library(nnet)
mlogit = multinom(Species ~ . , data = train_data)
summary(mlogit)
p = predict(mlogit, newdata = test_data)
summary(p)
table(test_data$Species)
help(fitted)
set.seed(1013)
train_index = sample(1:nrow(data), size = 100, replace = F)
train_data = data[train_index,]
str(train_data)
test_data = data[-train_index,]
levels(train_data$Species)
train_data$Species = relevel(train_data$Species, 'virginica')
library(nnet)
mlogit = multinom(Species ~ . , data = train_data)
summary(mlogit)
p = predict(mlogit, newdata = test_data)
summary(p)
table(test_data$Species)
help(fitted)
exp(coef(mlogit))
fit = fitted(mlogit)
fit
p = predict(mlogit, newdata = test_data, type='probs')
summary(p)
p
p = predict(mlogit, newdata = test_data, type='response')
p = predict(mlogit, newdata = test_data, type='class')
summary(p)
p
table(test_data$Species)
summary(p)
table(test_data$Species)
install.packages('survival')
library(survival)
str(colon)
data(survival)
data(colon)
colon
str(colon)
head(colon)
head(colon, 20)
head(colon, 20)
head(colon, 200)
library(gmodel)
library(gmodel)
library('gmodel')
install.packages('gmodel')
library(gmodels)
CrossTable(colon$status, colon$rx)
CrossTable(colon$status, colon$rx, chisq = TRUE)
df1 = colon(colon$etype == 1)
df1 = subset(colon, colon$etype == 1)
df1
df2 = subset(colon, colon$etype == 2)
str(colon)
summary(colon)
df = na.omit(str)
df1 = subset(df, colon$etype == 1)
df2 = subset(df, colon$etype == 2)
df1 = subset(df, df$etype == 1)
df2 = subset(df, df$etype == 2)
df
df = na.omit(colon)
df1 = subset(df, df$etype == 1)
df2 = subset(df, df$etype == 2)
df1
library(ggplot)
str(df1)
m = glm(status ~ . , data = df1)
summary(m)
df1 = subset(df[,-etype], df$etype == 1)
df1 = subset(df[,- df$etype], df$etype == 1)
df1
df1 = subset(df, df$etype == 1)
df1$etype = NULL
df2$etype = NULL
m = glm(status ~ . , data = df1)
summary(m)
df1 = subset(df, df$etype == 1, select= c(-etype, id))
df1 = subset(df, df$etype == 1, select= c(-etype, -id))
df1
df1 = subset(df, df$etype == 1, select= c(-etype, -id, -study))
m = glm(status ~ . , data = df1)
summary(m)
m = glm(status ~ . , data = df1, family = )
m = glm(status ~ . , data = df1, family = 'binomial')
summary(m)
str(df1)
summary(df)
str(df)
df_train_idx = sample(1:nrow(df), size=1000, replace=F)
df_train_data = df[train_idx,]
df_train_idx = sample(1:nrow(df), size=1000, replace=F)
df_train_data = df[train_idx,]
train_data = df[train_idx,]
train_idx = sample(1:nrow(df), size=1000, replace=F)
train_data = df[train_idx,]
str(train_data)
m1 = lm(status ~ . , data= train_data)
summary(m1)
df1 = subset(train_data, df$etype == 1, select= c(-etype, -id, -study))
m = glm(status ~ . , data = df1, family = 'binomial')
summary(m)
df = na.omit(colon)
summary(df)
str(df)
train_idx = sample(1:nrow(df), size=1000, replace=F)
train_data = df[train_idx,]
str(train_data)
summary(train_data)
df1 = subset(train_data, df$etype == 1, select= c(-etype, -id, -study))
m = glm(status ~ . , data = df1, family = 'binomial')
summary(m)
m = glm(status ~ . , data = df1, family = binomial(link = 'logit'))
summary(m)
m = glm(status ~ . , data = df1, family = binomial(link = 'probit'))
m = glm(status ~ . , data = df1, family = binomial(link = 'probit'))
summary(m)
str(df1)
df1 = subset(df, df$etype==1)
df2 = subset(df, df$etype==2)
summary(df1)
str(df1)
str(df2)
train_idx = sample(1:nrow(df1), size=666, replace=F)
train_data1 = df1[train_idx,]
train_data2 = df2[train_idx,]
str(train_data1)
summary(train_data1)
df_train1 = subset(train_data1, df$etype == 1, select= c(-etype, -id, -study))
str(df_train1)
m = glm(status ~ . , data = df_train1, family = binomial(link = 'probit'))
summary(m)
df_train1
getOption(max.print=1000)
getOption('max.print')
df_train1
m = glm(status ~ . , data = df_train2, family = binomial(link = 'probit'))
df_train1 = subset(train_data1, select= c(-etype, -id, -study))
df_train2 = subset(train_data2, select= c(-etype, -id, -study))
m = glm(status ~ . , data = df_train2, family = binomial(link = 'probit'))
summary(m)
m = glm(status ~ . , data = df_train1, family = binomial(link = 'probit'))
summary(m)
test_data1 = df1[-train_idx,]
predict(m, newdata = test_data1)
p = predict(m, newdata = test_data1, type='response')
p
m = glm(status ~ . , data = df_train1, family = binomial(link = 'probit'))
summary(m)
step.m = step(m)
str(train_data1)
p = predict(m, newdata=test_data1)
summary(p)
p = predict(m, newdata=test_data1, type='class')
p = predict(m, newdata=test_data1, type='response')
summary(p)
test_data1$result = p
test_data1
test_data1 = df1[-train_idx,]
result = subset(test_data1, status)
result = subset(test_data1, select = status)
result
result$result = p
result
summary(m)
m.step = step(m, direction = 'both')
p2 = predict(m.step, newdata=test_data1)
summary(p2)
p2 = predict(m.step, newdata=test_data1, type='response')
summary(p2)
result$result = p2
result
result$check = ifelse(result$result >0.5, 1, 0)
result
sum(result$status == result$check)
sum(result$status != result$check)
result = subset(test_data1, select = status)
result$result = p
result
result$check = ifelse(result$result >0.5, 1, 0)
sum(result$status == result$check)
sum(result$status != result$check)
summary(m.step)
install.packages('survival')
install.packages("survival")
#install.packages('survival')
library(survival)
str(colon)
str(colon)
head(colon, 200)
str(colon)
summary(colon)
df = na.omit(colon)
df_train1 = subset(train_data1, select= c(-etype, -id, -study, -time))
m = glm(status ~ . , data = df_train1, family = binomial(link = 'probit'))
summary(m)
df_train1 = subset(train_data1, select= c(-etype, -id, -study))
df_train2 = subset(train_data2, select= c(-etype, -id, -study))
m = glm(status ~ . , data = df_train1, family = binomial(link = 'probit'))
summary(m)
df1 = subset(df, df$etype==1)
df2 = subset(df, df$etype==2)
train_idx = sample(1:nrow(df1), size=666, replace=F)
train_data1 = df1[train_idx,]
train_data2 = df2[train_idx,]
test_data1 = df1[-train_idx,]
str(train_data1)
test_data2 = df2[-train_idx,]
df_train1 = subset(train_data1, select= c(-etype, -id, -study))
df_train2 = subset(train_data2, select= c(-etype, -id, -study))
m1 = glm(status ~ . , data = df_train1, family = binomial(link = 'probit'))
summary(m1)
df$time
df1 = subset(df, df$etype==1)
df2 = subset(df, df$etype==2)
train_idx = sample(1:nrow(df1), size=666, replace=F)
train_data1 = df1[train_idx,]
train_data2 = df2[train_idx,]
test_data1 = df1[-train_idx,]
test_data2 = df2[-train_idx,]
df_train1 = subset(train_data1, select= c(-etype, -id, -study))
df_train2 = subset(train_data2, select= c(-etype, -id, -study))
m1 = glm(status ~ . , data = df_train1, family = binomial(link = 'probit'))
summary(m1)
p = predict(m, newdata=test_data1, type='response')
summary(p)
df_train1 = subset(train_data1, select= c(-etype, -id, -study, -time))
m1 = glm(status ~ . , data = df_train1, family = binomial(link = 'probit'))
summary(m1)
p1 = predict(m1, newdata=test_data1, type='response')
summary(p1)
result = subset(test_data1, select = status)
result$result = p1
result
result$check = ifelse(result$result >0.5, 1, 0)
sum(result$status == result$check)
sum(result$status != result$check)
summary(m1)
result$result = p1
result$check = ifelse(result$result >0.5, 1, 0)
sum(result$status == result$check)
sum(result$status != result$check)
m.step = step(m, direction = 'both')
m.step = step(m1, direction = 'both')
m.step = step(m1, direction = 'both')
summary(m.step)
p2 = predict(m.step, newdata=test_data1, type='response')
summary(p2)
result$result = p2
result$check = ifelse(result$result >0.5, 1, 0)
sum(result$status == result$check)
sum(result$status != result$check)
demo()
data(iris)
idx = sample(1:nrow((iris)), 40)
irisSample = iris[idx,]
irisSample$Species = NULL
str(irisSample)
summary(irisSample)
hc = hclust(dist(irisSample), method='average')
plot(hc, hang = 1, labels=iris$Species[idx])
rect.hclust(hc, h=3)
rect.hclust(hc, h=2)
rect.hclust(hc, h=3)
rect.hclust(hc, h=4)
rect.hclust(hc, h=0)
rect.hclust(hc, h=1)
plot(hc, hang = 1, labels=iris$Species[idx])
rect.hclust(hc, h=1)
rect.hclust(hc, h=2)
rect.hclust(hc, h=1.6)
plot(hc, hang = 1, labels=iris$Species[idx])
rect.hclust(hc, h=1.6)
group = cutree(hc, k=3)
group
group = cutree(hc, k=4)
group
data("USArrests")
data("USArrests")
USArrests
dist(USArrests)
hc = hclust(dist(USArrests), method = 'average')
plot(hc, hang = 1)
plot(hc, hang = -1)
plot(hc, hang = 3)
plot(hc, hang = -1)
plot(hc, hang = -1, cex=0.6)
plot(hc, hang = -1, cex=1)
plot(hc, hang = -1, cex=0.7)
plot(hc, hang = -1, cex=0.8)
str(USArrests)
summary(USArrests)
rect.hclust(hc, h = 30)
rect.clear
rect.hclust.clear
plot(hc, hang = -1, cex=0.8)
rect.hclust(hc, h = 50)
rect.hclust(hc, k = 6, border = 'green')
plot(hc, hang = -1, cex=0.8)
rect.hclust(hc, h = 50)
USArrests
USArrests['Florida']
USArrests['Florida',]
USArrests['North Carolina',]
USArrests['Texas',]
USArrests['Colorado',]
?USArrests
str(USArrests)
summary(USArrests)
str(USArrests)
USArrests[49,]
USArrests[50,]
USArrests['Iowa',]
USArrests['New Hampsher',]
USArrests['New Hampshire',]
USArrests['Iowa',]
USArrests['New Hampshire',]
USArrests['Florida',]
USArrests['North Carolina',]
USArrests['Michigan',]
USArrests['Nevada',]
USArrests['Ohio',]
USArrests['Utah',]
plot(hc, hang = -1, cex=0.8)
rect.hclust(hc, h = 50)
USArrests['Virginia',]
USArrests['Oklahoma',]
USArrests['Florida',]
USArrests['North Carolina',]
colnames(USArrests)
rownames(USArrests)
USArrests['Florida',]
USArrests['North Carolina',]
USArrests['Michigan',]
USArrests['Nevada',]
USArrests['Virginia',]
USArrests['Oklahoma',]
USArrests['Ohio',]
USArrests['Utah',]
USArrests['Iowa',]
USArrests['New Hampshire',]
USArrests['New York',]
USArrests['Illinois',]
USArrests['West Virginia',]
USArrests['Maine',]
hc
USArrests['Hawai',]
USArrests['South Dakota',]
USArrests['North Dakota',]
USArrests['Vermont Dakota',]
USArrests['Vermont',]
USArrests['Minesota',]
USArrests['Minnes',]
USArrests['Kentu',]
USArrests['Monta',]
USArrests['North Ca',]
getwd()
setwd("C:\Users\kbh11\Desktop\Coding\Python_Experiment\project01\유가예측\data")
setwd("C:\\Users\\kbh11\\Desktop\\Coding\\Python_Experiment\\project01\\유가예측\\data")
data = read.csv('price_modified.csv', encoding = 'cp949')
data
str(data)
data$wti_modified
pricd = data$wti_modified
price
price = data$wti_modified
price
ts_price = ts(price)
ts_price
library(forecast)
library(tsseries)
install.packages(tsseries)
install.packages(tseries)
install.packages(tseries)
install.packages(ts_series)
?tseries
tseries::adf.test(ts_price)
tseries::kpss.test(ts_price)
arima = auto.arima(ts_price)
summary(arima)
ts_price = ts(price, start = c(1995,1), frequency = 1)
ts_price
ts_price = ts(price, start = c(1995,1), frequency = 1)
components = components(ts_price)
components = decompose(ts_price)
ts_price = ts(price, start = c(1995,1), frequency = 1)
components = decompose(ts_price)
ts_price = ts(price, )
components = decompose(ts_price)
start = c(1995,1), frequency = 1
start = c(1995,1), frequency = 1
ts_price = ts(price, start = c(1995,1), frequency = 1)
components = decompose(ts_price)
plot(ts_price)
price_diff = diff(ts_price)
plot(price_diff)
lot_diff = log(price_diff)
plot(ts_price)
lot_diff = log(ts_price)
plot(lot_diff)
log_diff = log(ts_price)
plot(log_diff)
price_diff = diff(log_diff)
plot(log_diff)
price_diff = diff(log_diff)
plot(log_diff)
log_diff = log(ts_price)
plot(log_diff)
plot(ts_price)
price_diff = diff(ts_price)
plot(ts_price)
plot(price_diff)
summary(arima)
acf(price_diff)
pacf(price_diff)
acf(price_diff)
